{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2851,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00350754121360926,
      "grad_norm": 2.5380330085754395,
      "learning_rate": 1.9929849175727814e-05,
      "loss": 1.114,
      "step": 10
    },
    {
      "epoch": 0.00701508242721852,
      "grad_norm": 1.7869329452514648,
      "learning_rate": 1.985969835145563e-05,
      "loss": 1.0845,
      "step": 20
    },
    {
      "epoch": 0.01052262364082778,
      "grad_norm": 1.6368988752365112,
      "learning_rate": 1.9789547527183446e-05,
      "loss": 1.0609,
      "step": 30
    },
    {
      "epoch": 0.01403016485443704,
      "grad_norm": 1.2032017707824707,
      "learning_rate": 1.971939670291126e-05,
      "loss": 1.047,
      "step": 40
    },
    {
      "epoch": 0.017537706068046298,
      "grad_norm": 1.1512702703475952,
      "learning_rate": 1.9649245878639075e-05,
      "loss": 1.0469,
      "step": 50
    },
    {
      "epoch": 0.02104524728165556,
      "grad_norm": 1.5240015983581543,
      "learning_rate": 1.957909505436689e-05,
      "loss": 1.0038,
      "step": 60
    },
    {
      "epoch": 0.024552788495264818,
      "grad_norm": 1.0384668111801147,
      "learning_rate": 1.9508944230094707e-05,
      "loss": 1.0166,
      "step": 70
    },
    {
      "epoch": 0.02806032970887408,
      "grad_norm": 1.801682472229004,
      "learning_rate": 1.943879340582252e-05,
      "loss": 0.9902,
      "step": 80
    },
    {
      "epoch": 0.03156787092248334,
      "grad_norm": 2.125518560409546,
      "learning_rate": 1.9368642581550336e-05,
      "loss": 1.0069,
      "step": 90
    },
    {
      "epoch": 0.035075412136092596,
      "grad_norm": 1.0267977714538574,
      "learning_rate": 1.929849175727815e-05,
      "loss": 1.0065,
      "step": 100
    },
    {
      "epoch": 0.03858295334970186,
      "grad_norm": 1.8041901588439941,
      "learning_rate": 1.9228340933005964e-05,
      "loss": 1.0085,
      "step": 110
    },
    {
      "epoch": 0.04209049456331112,
      "grad_norm": 1.7377955913543701,
      "learning_rate": 1.9158190108733777e-05,
      "loss": 1.0172,
      "step": 120
    },
    {
      "epoch": 0.04559803577692038,
      "grad_norm": 1.648505687713623,
      "learning_rate": 1.9088039284461596e-05,
      "loss": 0.975,
      "step": 130
    },
    {
      "epoch": 0.049105576990529635,
      "grad_norm": 1.0232501029968262,
      "learning_rate": 1.901788846018941e-05,
      "loss": 1.0451,
      "step": 140
    },
    {
      "epoch": 0.0526131182041389,
      "grad_norm": 2.0818161964416504,
      "learning_rate": 1.894773763591722e-05,
      "loss": 0.9728,
      "step": 150
    },
    {
      "epoch": 0.05612065941774816,
      "grad_norm": 1.6849421262741089,
      "learning_rate": 1.8877586811645038e-05,
      "loss": 0.9615,
      "step": 160
    },
    {
      "epoch": 0.05962820063135742,
      "grad_norm": 1.1742675304412842,
      "learning_rate": 1.8807435987372854e-05,
      "loss": 1.0332,
      "step": 170
    },
    {
      "epoch": 0.06313574184496668,
      "grad_norm": 1.1313750743865967,
      "learning_rate": 1.8737285163100666e-05,
      "loss": 0.9759,
      "step": 180
    },
    {
      "epoch": 0.06664328305857593,
      "grad_norm": 1.4375287294387817,
      "learning_rate": 1.8667134338828482e-05,
      "loss": 1.0028,
      "step": 190
    },
    {
      "epoch": 0.07015082427218519,
      "grad_norm": 2.0819761753082275,
      "learning_rate": 1.85969835145563e-05,
      "loss": 0.9396,
      "step": 200
    },
    {
      "epoch": 0.07365836548579446,
      "grad_norm": 1.42951238155365,
      "learning_rate": 1.8526832690284114e-05,
      "loss": 1.0115,
      "step": 210
    },
    {
      "epoch": 0.07716590669940372,
      "grad_norm": 1.12897527217865,
      "learning_rate": 1.8456681866011927e-05,
      "loss": 0.9826,
      "step": 220
    },
    {
      "epoch": 0.08067344791301298,
      "grad_norm": 1.6820725202560425,
      "learning_rate": 1.8386531041739743e-05,
      "loss": 0.9919,
      "step": 230
    },
    {
      "epoch": 0.08418098912662224,
      "grad_norm": 1.3203256130218506,
      "learning_rate": 1.831638021746756e-05,
      "loss": 0.9417,
      "step": 240
    },
    {
      "epoch": 0.0876885303402315,
      "grad_norm": 1.726773738861084,
      "learning_rate": 1.824622939319537e-05,
      "loss": 0.9756,
      "step": 250
    },
    {
      "epoch": 0.09119607155384075,
      "grad_norm": 2.417121171951294,
      "learning_rate": 1.8176078568923184e-05,
      "loss": 0.9873,
      "step": 260
    },
    {
      "epoch": 0.09470361276745001,
      "grad_norm": 2.8429007530212402,
      "learning_rate": 1.8105927744651e-05,
      "loss": 0.9335,
      "step": 270
    },
    {
      "epoch": 0.09821115398105927,
      "grad_norm": 1.1232411861419678,
      "learning_rate": 1.8035776920378816e-05,
      "loss": 0.9206,
      "step": 280
    },
    {
      "epoch": 0.10171869519466854,
      "grad_norm": 1.2667051553726196,
      "learning_rate": 1.796562609610663e-05,
      "loss": 0.8937,
      "step": 290
    },
    {
      "epoch": 0.1052262364082778,
      "grad_norm": 1.7625758647918701,
      "learning_rate": 1.7895475271834445e-05,
      "loss": 0.9126,
      "step": 300
    },
    {
      "epoch": 0.10873377762188706,
      "grad_norm": 1.5830068588256836,
      "learning_rate": 1.782532444756226e-05,
      "loss": 0.9327,
      "step": 310
    },
    {
      "epoch": 0.11224131883549632,
      "grad_norm": 2.3855338096618652,
      "learning_rate": 1.7755173623290077e-05,
      "loss": 0.9725,
      "step": 320
    },
    {
      "epoch": 0.11574886004910558,
      "grad_norm": 2.043015718460083,
      "learning_rate": 1.768502279901789e-05,
      "loss": 0.8744,
      "step": 330
    },
    {
      "epoch": 0.11925640126271483,
      "grad_norm": 2.5712122917175293,
      "learning_rate": 1.7614871974745706e-05,
      "loss": 0.8841,
      "step": 340
    },
    {
      "epoch": 0.12276394247632409,
      "grad_norm": 1.462308645248413,
      "learning_rate": 1.754472115047352e-05,
      "loss": 0.9124,
      "step": 350
    },
    {
      "epoch": 0.12627148368993335,
      "grad_norm": 1.3627766370773315,
      "learning_rate": 1.7474570326201334e-05,
      "loss": 0.8736,
      "step": 360
    },
    {
      "epoch": 0.12977902490354262,
      "grad_norm": 1.9682939052581787,
      "learning_rate": 1.7404419501929147e-05,
      "loss": 0.8958,
      "step": 370
    },
    {
      "epoch": 0.13328656611715187,
      "grad_norm": 1.5803756713867188,
      "learning_rate": 1.7334268677656963e-05,
      "loss": 0.885,
      "step": 380
    },
    {
      "epoch": 0.13679410733076114,
      "grad_norm": 1.6160285472869873,
      "learning_rate": 1.726411785338478e-05,
      "loss": 0.8751,
      "step": 390
    },
    {
      "epoch": 0.14030164854437038,
      "grad_norm": 1.974269986152649,
      "learning_rate": 1.719396702911259e-05,
      "loss": 0.8382,
      "step": 400
    },
    {
      "epoch": 0.14380918975797966,
      "grad_norm": 1.9646025896072388,
      "learning_rate": 1.7123816204840408e-05,
      "loss": 0.8436,
      "step": 410
    },
    {
      "epoch": 0.14731673097158893,
      "grad_norm": 2.418581962585449,
      "learning_rate": 1.7053665380568224e-05,
      "loss": 0.8112,
      "step": 420
    },
    {
      "epoch": 0.15082427218519817,
      "grad_norm": 1.6606066226959229,
      "learning_rate": 1.6983514556296036e-05,
      "loss": 0.84,
      "step": 430
    },
    {
      "epoch": 0.15433181339880744,
      "grad_norm": 2.490370273590088,
      "learning_rate": 1.6913363732023852e-05,
      "loss": 0.8063,
      "step": 440
    },
    {
      "epoch": 0.1578393546124167,
      "grad_norm": 2.8166325092315674,
      "learning_rate": 1.684321290775167e-05,
      "loss": 0.7709,
      "step": 450
    },
    {
      "epoch": 0.16134689582602596,
      "grad_norm": 2.598790407180786,
      "learning_rate": 1.6773062083479484e-05,
      "loss": 0.8342,
      "step": 460
    },
    {
      "epoch": 0.1648544370396352,
      "grad_norm": 3.7865118980407715,
      "learning_rate": 1.6702911259207297e-05,
      "loss": 0.8256,
      "step": 470
    },
    {
      "epoch": 0.16836197825324448,
      "grad_norm": 2.8322155475616455,
      "learning_rate": 1.663276043493511e-05,
      "loss": 0.8508,
      "step": 480
    },
    {
      "epoch": 0.17186951946685375,
      "grad_norm": 3.96136736869812,
      "learning_rate": 1.656260961066293e-05,
      "loss": 0.8109,
      "step": 490
    },
    {
      "epoch": 0.175377060680463,
      "grad_norm": 3.4276320934295654,
      "learning_rate": 1.649245878639074e-05,
      "loss": 0.8946,
      "step": 500
    },
    {
      "epoch": 0.17888460189407226,
      "grad_norm": 5.05963659286499,
      "learning_rate": 1.6422307962118554e-05,
      "loss": 0.8078,
      "step": 510
    },
    {
      "epoch": 0.1823921431076815,
      "grad_norm": 3.170315742492676,
      "learning_rate": 1.635215713784637e-05,
      "loss": 0.8159,
      "step": 520
    },
    {
      "epoch": 0.18589968432129078,
      "grad_norm": 5.918566703796387,
      "learning_rate": 1.6282006313574186e-05,
      "loss": 0.764,
      "step": 530
    },
    {
      "epoch": 0.18940722553490003,
      "grad_norm": 2.234618902206421,
      "learning_rate": 1.6211855489302e-05,
      "loss": 0.7593,
      "step": 540
    },
    {
      "epoch": 0.1929147667485093,
      "grad_norm": 2.0252583026885986,
      "learning_rate": 1.6141704665029815e-05,
      "loss": 0.8001,
      "step": 550
    },
    {
      "epoch": 0.19642230796211854,
      "grad_norm": 3.3837974071502686,
      "learning_rate": 1.607155384075763e-05,
      "loss": 0.8261,
      "step": 560
    },
    {
      "epoch": 0.19992984917572781,
      "grad_norm": 4.271028995513916,
      "learning_rate": 1.6001403016485444e-05,
      "loss": 0.7723,
      "step": 570
    },
    {
      "epoch": 0.20343739038933709,
      "grad_norm": 3.793081045150757,
      "learning_rate": 1.593125219221326e-05,
      "loss": 0.7995,
      "step": 580
    },
    {
      "epoch": 0.20694493160294633,
      "grad_norm": 5.394029140472412,
      "learning_rate": 1.5861101367941076e-05,
      "loss": 0.7307,
      "step": 590
    },
    {
      "epoch": 0.2104524728165556,
      "grad_norm": 7.461060523986816,
      "learning_rate": 1.579095054366889e-05,
      "loss": 0.8184,
      "step": 600
    },
    {
      "epoch": 0.21396001403016485,
      "grad_norm": 2.8094263076782227,
      "learning_rate": 1.5720799719396704e-05,
      "loss": 0.7226,
      "step": 610
    },
    {
      "epoch": 0.21746755524377412,
      "grad_norm": 4.828051567077637,
      "learning_rate": 1.5650648895124517e-05,
      "loss": 0.8227,
      "step": 620
    },
    {
      "epoch": 0.22097509645738336,
      "grad_norm": 2.4170281887054443,
      "learning_rate": 1.5580498070852333e-05,
      "loss": 0.8273,
      "step": 630
    },
    {
      "epoch": 0.22448263767099264,
      "grad_norm": 2.3241491317749023,
      "learning_rate": 1.551034724658015e-05,
      "loss": 0.7881,
      "step": 640
    },
    {
      "epoch": 0.2279901788846019,
      "grad_norm": 4.96527099609375,
      "learning_rate": 1.544019642230796e-05,
      "loss": 0.8718,
      "step": 650
    },
    {
      "epoch": 0.23149772009821115,
      "grad_norm": 2.6731934547424316,
      "learning_rate": 1.5370045598035778e-05,
      "loss": 0.7679,
      "step": 660
    },
    {
      "epoch": 0.23500526131182042,
      "grad_norm": 2.8569977283477783,
      "learning_rate": 1.5299894773763594e-05,
      "loss": 0.8134,
      "step": 670
    },
    {
      "epoch": 0.23851280252542967,
      "grad_norm": 6.029683589935303,
      "learning_rate": 1.5229743949491406e-05,
      "loss": 0.823,
      "step": 680
    },
    {
      "epoch": 0.24202034373903894,
      "grad_norm": 5.428136348724365,
      "learning_rate": 1.5159593125219222e-05,
      "loss": 0.7299,
      "step": 690
    },
    {
      "epoch": 0.24552788495264818,
      "grad_norm": 7.704301834106445,
      "learning_rate": 1.5089442300947037e-05,
      "loss": 0.7835,
      "step": 700
    },
    {
      "epoch": 0.24903542616625746,
      "grad_norm": 3.6614935398101807,
      "learning_rate": 1.5019291476674853e-05,
      "loss": 0.7346,
      "step": 710
    },
    {
      "epoch": 0.2525429673798667,
      "grad_norm": 3.2144086360931396,
      "learning_rate": 1.4949140652402667e-05,
      "loss": 0.7853,
      "step": 720
    },
    {
      "epoch": 0.256050508593476,
      "grad_norm": 4.748734951019287,
      "learning_rate": 1.4878989828130481e-05,
      "loss": 0.7885,
      "step": 730
    },
    {
      "epoch": 0.25955804980708524,
      "grad_norm": 2.147331476211548,
      "learning_rate": 1.4808839003858297e-05,
      "loss": 0.743,
      "step": 740
    },
    {
      "epoch": 0.2630655910206945,
      "grad_norm": 3.5350635051727295,
      "learning_rate": 1.4738688179586112e-05,
      "loss": 0.7702,
      "step": 750
    },
    {
      "epoch": 0.26657313223430373,
      "grad_norm": 4.427053451538086,
      "learning_rate": 1.4668537355313926e-05,
      "loss": 0.8318,
      "step": 760
    },
    {
      "epoch": 0.27008067344791303,
      "grad_norm": 3.7876644134521484,
      "learning_rate": 1.4598386531041742e-05,
      "loss": 0.7122,
      "step": 770
    },
    {
      "epoch": 0.2735882146615223,
      "grad_norm": 4.340315341949463,
      "learning_rate": 1.4528235706769556e-05,
      "loss": 0.7258,
      "step": 780
    },
    {
      "epoch": 0.2770957558751315,
      "grad_norm": 6.698873519897461,
      "learning_rate": 1.4458084882497369e-05,
      "loss": 0.7706,
      "step": 790
    },
    {
      "epoch": 0.28060329708874077,
      "grad_norm": 5.088537216186523,
      "learning_rate": 1.4387934058225187e-05,
      "loss": 0.7951,
      "step": 800
    },
    {
      "epoch": 0.28411083830235007,
      "grad_norm": 4.019773960113525,
      "learning_rate": 1.4317783233953e-05,
      "loss": 0.6991,
      "step": 810
    },
    {
      "epoch": 0.2876183795159593,
      "grad_norm": 3.1690170764923096,
      "learning_rate": 1.4247632409680814e-05,
      "loss": 0.7666,
      "step": 820
    },
    {
      "epoch": 0.29112592072956855,
      "grad_norm": 3.9480185508728027,
      "learning_rate": 1.417748158540863e-05,
      "loss": 0.6808,
      "step": 830
    },
    {
      "epoch": 0.29463346194317785,
      "grad_norm": 4.7857136726379395,
      "learning_rate": 1.4107330761136444e-05,
      "loss": 0.7543,
      "step": 840
    },
    {
      "epoch": 0.2981410031567871,
      "grad_norm": 4.571056365966797,
      "learning_rate": 1.403717993686426e-05,
      "loss": 0.7376,
      "step": 850
    },
    {
      "epoch": 0.30164854437039634,
      "grad_norm": 3.5079052448272705,
      "learning_rate": 1.3967029112592074e-05,
      "loss": 0.7456,
      "step": 860
    },
    {
      "epoch": 0.3051560855840056,
      "grad_norm": 3.067321538925171,
      "learning_rate": 1.3896878288319889e-05,
      "loss": 0.8251,
      "step": 870
    },
    {
      "epoch": 0.3086636267976149,
      "grad_norm": 2.3409032821655273,
      "learning_rate": 1.3826727464047705e-05,
      "loss": 0.8379,
      "step": 880
    },
    {
      "epoch": 0.31217116801122413,
      "grad_norm": 3.921119451522827,
      "learning_rate": 1.3756576639775519e-05,
      "loss": 0.6685,
      "step": 890
    },
    {
      "epoch": 0.3156787092248334,
      "grad_norm": 3.1541168689727783,
      "learning_rate": 1.3686425815503333e-05,
      "loss": 0.6694,
      "step": 900
    },
    {
      "epoch": 0.3191862504384427,
      "grad_norm": 2.751974105834961,
      "learning_rate": 1.361627499123115e-05,
      "loss": 0.6771,
      "step": 910
    },
    {
      "epoch": 0.3226937916520519,
      "grad_norm": 4.863887310028076,
      "learning_rate": 1.3546124166958962e-05,
      "loss": 0.7746,
      "step": 920
    },
    {
      "epoch": 0.32620133286566116,
      "grad_norm": 2.6464812755584717,
      "learning_rate": 1.3475973342686776e-05,
      "loss": 0.7065,
      "step": 930
    },
    {
      "epoch": 0.3297088740792704,
      "grad_norm": 2.8559982776641846,
      "learning_rate": 1.3405822518414592e-05,
      "loss": 0.5967,
      "step": 940
    },
    {
      "epoch": 0.3332164152928797,
      "grad_norm": 3.567251205444336,
      "learning_rate": 1.3335671694142407e-05,
      "loss": 0.6686,
      "step": 950
    },
    {
      "epoch": 0.33672395650648895,
      "grad_norm": 2.315936326980591,
      "learning_rate": 1.3265520869870223e-05,
      "loss": 0.6846,
      "step": 960
    },
    {
      "epoch": 0.3402314977200982,
      "grad_norm": 5.689930438995361,
      "learning_rate": 1.3195370045598037e-05,
      "loss": 0.7094,
      "step": 970
    },
    {
      "epoch": 0.3437390389337075,
      "grad_norm": 4.038802146911621,
      "learning_rate": 1.3125219221325851e-05,
      "loss": 0.7278,
      "step": 980
    },
    {
      "epoch": 0.34724658014731674,
      "grad_norm": 4.872319221496582,
      "learning_rate": 1.3055068397053667e-05,
      "loss": 0.7694,
      "step": 990
    },
    {
      "epoch": 0.350754121360926,
      "grad_norm": 2.8711307048797607,
      "learning_rate": 1.2984917572781482e-05,
      "loss": 0.7768,
      "step": 1000
    },
    {
      "epoch": 0.35426166257453523,
      "grad_norm": 3.4472551345825195,
      "learning_rate": 1.2914766748509296e-05,
      "loss": 0.7811,
      "step": 1010
    },
    {
      "epoch": 0.35776920378814453,
      "grad_norm": 3.178251266479492,
      "learning_rate": 1.2844615924237112e-05,
      "loss": 0.8174,
      "step": 1020
    },
    {
      "epoch": 0.3612767450017538,
      "grad_norm": 3.0705487728118896,
      "learning_rate": 1.2774465099964926e-05,
      "loss": 0.682,
      "step": 1030
    },
    {
      "epoch": 0.364784286215363,
      "grad_norm": 8.066139221191406,
      "learning_rate": 1.2704314275692739e-05,
      "loss": 0.7829,
      "step": 1040
    },
    {
      "epoch": 0.3682918274289723,
      "grad_norm": 6.551990509033203,
      "learning_rate": 1.2634163451420555e-05,
      "loss": 0.7501,
      "step": 1050
    },
    {
      "epoch": 0.37179936864258156,
      "grad_norm": 3.4605705738067627,
      "learning_rate": 1.256401262714837e-05,
      "loss": 0.7214,
      "step": 1060
    },
    {
      "epoch": 0.3753069098561908,
      "grad_norm": 2.753054618835449,
      "learning_rate": 1.2493861802876184e-05,
      "loss": 0.6984,
      "step": 1070
    },
    {
      "epoch": 0.37881445106980005,
      "grad_norm": 3.5672104358673096,
      "learning_rate": 1.2423710978604e-05,
      "loss": 0.7277,
      "step": 1080
    },
    {
      "epoch": 0.38232199228340935,
      "grad_norm": 4.290671348571777,
      "learning_rate": 1.2353560154331814e-05,
      "loss": 0.6806,
      "step": 1090
    },
    {
      "epoch": 0.3858295334970186,
      "grad_norm": 5.411487102508545,
      "learning_rate": 1.228340933005963e-05,
      "loss": 0.7346,
      "step": 1100
    },
    {
      "epoch": 0.38933707471062784,
      "grad_norm": 4.256892204284668,
      "learning_rate": 1.2213258505787444e-05,
      "loss": 0.7181,
      "step": 1110
    },
    {
      "epoch": 0.3928446159242371,
      "grad_norm": 6.58331298828125,
      "learning_rate": 1.2143107681515259e-05,
      "loss": 0.717,
      "step": 1120
    },
    {
      "epoch": 0.3963521571378464,
      "grad_norm": 4.551059246063232,
      "learning_rate": 1.2072956857243075e-05,
      "loss": 0.8611,
      "step": 1130
    },
    {
      "epoch": 0.39985969835145563,
      "grad_norm": 8.09610366821289,
      "learning_rate": 1.2002806032970889e-05,
      "loss": 0.7577,
      "step": 1140
    },
    {
      "epoch": 0.4033672395650649,
      "grad_norm": 4.052328109741211,
      "learning_rate": 1.1932655208698702e-05,
      "loss": 0.7016,
      "step": 1150
    },
    {
      "epoch": 0.40687478077867417,
      "grad_norm": 4.033259868621826,
      "learning_rate": 1.186250438442652e-05,
      "loss": 0.7232,
      "step": 1160
    },
    {
      "epoch": 0.4103823219922834,
      "grad_norm": 3.9908294677734375,
      "learning_rate": 1.1792353560154332e-05,
      "loss": 0.6907,
      "step": 1170
    },
    {
      "epoch": 0.41388986320589266,
      "grad_norm": 5.202282428741455,
      "learning_rate": 1.1722202735882146e-05,
      "loss": 0.811,
      "step": 1180
    },
    {
      "epoch": 0.4173974044195019,
      "grad_norm": 7.834173679351807,
      "learning_rate": 1.1652051911609962e-05,
      "loss": 0.771,
      "step": 1190
    },
    {
      "epoch": 0.4209049456331112,
      "grad_norm": 6.319387912750244,
      "learning_rate": 1.1581901087337777e-05,
      "loss": 0.6974,
      "step": 1200
    },
    {
      "epoch": 0.42441248684672045,
      "grad_norm": 2.90392804145813,
      "learning_rate": 1.1511750263065593e-05,
      "loss": 0.6748,
      "step": 1210
    },
    {
      "epoch": 0.4279200280603297,
      "grad_norm": 4.933822154998779,
      "learning_rate": 1.1441599438793407e-05,
      "loss": 0.6895,
      "step": 1220
    },
    {
      "epoch": 0.431427569273939,
      "grad_norm": 7.057565689086914,
      "learning_rate": 1.1371448614521221e-05,
      "loss": 0.7764,
      "step": 1230
    },
    {
      "epoch": 0.43493511048754824,
      "grad_norm": 5.137789726257324,
      "learning_rate": 1.1301297790249037e-05,
      "loss": 0.7407,
      "step": 1240
    },
    {
      "epoch": 0.4384426517011575,
      "grad_norm": 5.093306541442871,
      "learning_rate": 1.1231146965976852e-05,
      "loss": 0.7862,
      "step": 1250
    },
    {
      "epoch": 0.4419501929147667,
      "grad_norm": 5.730232238769531,
      "learning_rate": 1.1160996141704666e-05,
      "loss": 0.7849,
      "step": 1260
    },
    {
      "epoch": 0.445457734128376,
      "grad_norm": 4.888377666473389,
      "learning_rate": 1.1090845317432482e-05,
      "loss": 0.7189,
      "step": 1270
    },
    {
      "epoch": 0.44896527534198527,
      "grad_norm": 2.770772695541382,
      "learning_rate": 1.1020694493160295e-05,
      "loss": 0.6633,
      "step": 1280
    },
    {
      "epoch": 0.4524728165555945,
      "grad_norm": 5.934732437133789,
      "learning_rate": 1.0950543668888109e-05,
      "loss": 0.7187,
      "step": 1290
    },
    {
      "epoch": 0.4559803577692038,
      "grad_norm": 3.673140287399292,
      "learning_rate": 1.0880392844615925e-05,
      "loss": 0.6768,
      "step": 1300
    },
    {
      "epoch": 0.45948789898281306,
      "grad_norm": 2.861924648284912,
      "learning_rate": 1.081024202034374e-05,
      "loss": 0.7542,
      "step": 1310
    },
    {
      "epoch": 0.4629954401964223,
      "grad_norm": 4.427435398101807,
      "learning_rate": 1.0740091196071554e-05,
      "loss": 0.6705,
      "step": 1320
    },
    {
      "epoch": 0.46650298141003155,
      "grad_norm": 3.7197675704956055,
      "learning_rate": 1.066994037179937e-05,
      "loss": 0.8089,
      "step": 1330
    },
    {
      "epoch": 0.47001052262364085,
      "grad_norm": 4.103642463684082,
      "learning_rate": 1.0599789547527184e-05,
      "loss": 0.6965,
      "step": 1340
    },
    {
      "epoch": 0.4735180638372501,
      "grad_norm": 3.737741231918335,
      "learning_rate": 1.0529638723255e-05,
      "loss": 0.788,
      "step": 1350
    },
    {
      "epoch": 0.47702560505085934,
      "grad_norm": 2.871875047683716,
      "learning_rate": 1.0459487898982814e-05,
      "loss": 0.7175,
      "step": 1360
    },
    {
      "epoch": 0.4805331462644686,
      "grad_norm": 3.176041603088379,
      "learning_rate": 1.0389337074710629e-05,
      "loss": 0.7746,
      "step": 1370
    },
    {
      "epoch": 0.4840406874780779,
      "grad_norm": 5.719819068908691,
      "learning_rate": 1.0319186250438445e-05,
      "loss": 0.7744,
      "step": 1380
    },
    {
      "epoch": 0.4875482286916871,
      "grad_norm": 4.2876482009887695,
      "learning_rate": 1.0249035426166259e-05,
      "loss": 0.7742,
      "step": 1390
    },
    {
      "epoch": 0.49105576990529637,
      "grad_norm": 2.407595634460449,
      "learning_rate": 1.0178884601894072e-05,
      "loss": 0.6671,
      "step": 1400
    },
    {
      "epoch": 0.49456331111890567,
      "grad_norm": 6.58709192276001,
      "learning_rate": 1.010873377762189e-05,
      "loss": 0.7555,
      "step": 1410
    },
    {
      "epoch": 0.4980708523325149,
      "grad_norm": 4.727895736694336,
      "learning_rate": 1.0038582953349702e-05,
      "loss": 0.6802,
      "step": 1420
    },
    {
      "epoch": 0.5015783935461242,
      "grad_norm": 3.668121337890625,
      "learning_rate": 9.968432129077518e-06,
      "loss": 0.695,
      "step": 1430
    },
    {
      "epoch": 0.5050859347597334,
      "grad_norm": 2.779141426086426,
      "learning_rate": 9.898281304805332e-06,
      "loss": 0.7497,
      "step": 1440
    },
    {
      "epoch": 0.5085934759733427,
      "grad_norm": 2.8723416328430176,
      "learning_rate": 9.828130480533147e-06,
      "loss": 0.69,
      "step": 1450
    },
    {
      "epoch": 0.512101017186952,
      "grad_norm": 4.8378705978393555,
      "learning_rate": 9.757979656260963e-06,
      "loss": 0.7328,
      "step": 1460
    },
    {
      "epoch": 0.5156085584005612,
      "grad_norm": 8.348947525024414,
      "learning_rate": 9.687828831988777e-06,
      "loss": 0.7074,
      "step": 1470
    },
    {
      "epoch": 0.5191160996141705,
      "grad_norm": 4.11031436920166,
      "learning_rate": 9.617678007716591e-06,
      "loss": 0.7078,
      "step": 1480
    },
    {
      "epoch": 0.5226236408277797,
      "grad_norm": 3.501154661178589,
      "learning_rate": 9.547527183444406e-06,
      "loss": 0.6455,
      "step": 1490
    },
    {
      "epoch": 0.526131182041389,
      "grad_norm": 3.3930325508117676,
      "learning_rate": 9.477376359172222e-06,
      "loss": 0.7565,
      "step": 1500
    },
    {
      "epoch": 0.5296387232549983,
      "grad_norm": 3.2560272216796875,
      "learning_rate": 9.407225534900036e-06,
      "loss": 0.6681,
      "step": 1510
    },
    {
      "epoch": 0.5331462644686075,
      "grad_norm": 5.684196472167969,
      "learning_rate": 9.33707471062785e-06,
      "loss": 0.6588,
      "step": 1520
    },
    {
      "epoch": 0.5366538056822168,
      "grad_norm": 3.488802194595337,
      "learning_rate": 9.266923886355665e-06,
      "loss": 0.7496,
      "step": 1530
    },
    {
      "epoch": 0.5401613468958261,
      "grad_norm": 5.1671977043151855,
      "learning_rate": 9.19677306208348e-06,
      "loss": 0.744,
      "step": 1540
    },
    {
      "epoch": 0.5436688881094353,
      "grad_norm": 2.2790279388427734,
      "learning_rate": 9.126622237811295e-06,
      "loss": 0.743,
      "step": 1550
    },
    {
      "epoch": 0.5471764293230446,
      "grad_norm": 4.582520484924316,
      "learning_rate": 9.05647141353911e-06,
      "loss": 0.7472,
      "step": 1560
    },
    {
      "epoch": 0.5506839705366539,
      "grad_norm": 2.9441847801208496,
      "learning_rate": 8.986320589266925e-06,
      "loss": 0.7479,
      "step": 1570
    },
    {
      "epoch": 0.554191511750263,
      "grad_norm": 6.339580535888672,
      "learning_rate": 8.91616976499474e-06,
      "loss": 0.7271,
      "step": 1580
    },
    {
      "epoch": 0.5576990529638723,
      "grad_norm": 3.694035768508911,
      "learning_rate": 8.846018940722554e-06,
      "loss": 0.7722,
      "step": 1590
    },
    {
      "epoch": 0.5612065941774815,
      "grad_norm": 4.6687822341918945,
      "learning_rate": 8.775868116450368e-06,
      "loss": 0.7542,
      "step": 1600
    },
    {
      "epoch": 0.5647141353910908,
      "grad_norm": 3.2926273345947266,
      "learning_rate": 8.705717292178184e-06,
      "loss": 0.7519,
      "step": 1610
    },
    {
      "epoch": 0.5682216766047001,
      "grad_norm": 3.272719621658325,
      "learning_rate": 8.635566467905999e-06,
      "loss": 0.6509,
      "step": 1620
    },
    {
      "epoch": 0.5717292178183093,
      "grad_norm": 7.679244518280029,
      "learning_rate": 8.565415643633813e-06,
      "loss": 0.7243,
      "step": 1630
    },
    {
      "epoch": 0.5752367590319186,
      "grad_norm": 2.9625613689422607,
      "learning_rate": 8.495264819361629e-06,
      "loss": 0.793,
      "step": 1640
    },
    {
      "epoch": 0.5787443002455279,
      "grad_norm": 3.174895763397217,
      "learning_rate": 8.425113995089443e-06,
      "loss": 0.7045,
      "step": 1650
    },
    {
      "epoch": 0.5822518414591371,
      "grad_norm": 2.136945962905884,
      "learning_rate": 8.354963170817258e-06,
      "loss": 0.7791,
      "step": 1660
    },
    {
      "epoch": 0.5857593826727464,
      "grad_norm": 3.989420175552368,
      "learning_rate": 8.284812346545072e-06,
      "loss": 0.739,
      "step": 1670
    },
    {
      "epoch": 0.5892669238863557,
      "grad_norm": 3.7161104679107666,
      "learning_rate": 8.214661522272888e-06,
      "loss": 0.6657,
      "step": 1680
    },
    {
      "epoch": 0.5927744650999649,
      "grad_norm": 3.6519598960876465,
      "learning_rate": 8.144510698000702e-06,
      "loss": 0.7904,
      "step": 1690
    },
    {
      "epoch": 0.5962820063135742,
      "grad_norm": 5.255668640136719,
      "learning_rate": 8.074359873728517e-06,
      "loss": 0.7508,
      "step": 1700
    },
    {
      "epoch": 0.5997895475271835,
      "grad_norm": 2.9637975692749023,
      "learning_rate": 8.004209049456331e-06,
      "loss": 0.669,
      "step": 1710
    },
    {
      "epoch": 0.6032970887407927,
      "grad_norm": 4.130792140960693,
      "learning_rate": 7.934058225184147e-06,
      "loss": 0.6457,
      "step": 1720
    },
    {
      "epoch": 0.606804629954402,
      "grad_norm": 4.678801536560059,
      "learning_rate": 7.863907400911961e-06,
      "loss": 0.6899,
      "step": 1730
    },
    {
      "epoch": 0.6103121711680112,
      "grad_norm": 4.770616054534912,
      "learning_rate": 7.793756576639776e-06,
      "loss": 0.7976,
      "step": 1740
    },
    {
      "epoch": 0.6138197123816205,
      "grad_norm": 4.572371006011963,
      "learning_rate": 7.723605752367592e-06,
      "loss": 0.7359,
      "step": 1750
    },
    {
      "epoch": 0.6173272535952298,
      "grad_norm": 3.049435615539551,
      "learning_rate": 7.653454928095406e-06,
      "loss": 0.724,
      "step": 1760
    },
    {
      "epoch": 0.620834794808839,
      "grad_norm": 4.47560453414917,
      "learning_rate": 7.58330410382322e-06,
      "loss": 0.7046,
      "step": 1770
    },
    {
      "epoch": 0.6243423360224483,
      "grad_norm": 4.952200412750244,
      "learning_rate": 7.5131532795510355e-06,
      "loss": 0.767,
      "step": 1780
    },
    {
      "epoch": 0.6278498772360576,
      "grad_norm": 2.698021411895752,
      "learning_rate": 7.443002455278851e-06,
      "loss": 0.702,
      "step": 1790
    },
    {
      "epoch": 0.6313574184496668,
      "grad_norm": 5.290701389312744,
      "learning_rate": 7.372851631006664e-06,
      "loss": 0.778,
      "step": 1800
    },
    {
      "epoch": 0.634864959663276,
      "grad_norm": 4.091232776641846,
      "learning_rate": 7.302700806734479e-06,
      "loss": 0.7578,
      "step": 1810
    },
    {
      "epoch": 0.6383725008768854,
      "grad_norm": 2.4417333602905273,
      "learning_rate": 7.2325499824622945e-06,
      "loss": 0.7422,
      "step": 1820
    },
    {
      "epoch": 0.6418800420904945,
      "grad_norm": 2.603593587875366,
      "learning_rate": 7.16239915819011e-06,
      "loss": 0.6892,
      "step": 1830
    },
    {
      "epoch": 0.6453875833041038,
      "grad_norm": 3.602193593978882,
      "learning_rate": 7.092248333917924e-06,
      "loss": 0.7062,
      "step": 1840
    },
    {
      "epoch": 0.648895124517713,
      "grad_norm": 4.326742649078369,
      "learning_rate": 7.022097509645739e-06,
      "loss": 0.726,
      "step": 1850
    },
    {
      "epoch": 0.6524026657313223,
      "grad_norm": 3.085150718688965,
      "learning_rate": 6.951946685373554e-06,
      "loss": 0.8484,
      "step": 1860
    },
    {
      "epoch": 0.6559102069449316,
      "grad_norm": 4.405165195465088,
      "learning_rate": 6.881795861101368e-06,
      "loss": 0.737,
      "step": 1870
    },
    {
      "epoch": 0.6594177481585408,
      "grad_norm": 2.6098740100860596,
      "learning_rate": 6.811645036829183e-06,
      "loss": 0.6826,
      "step": 1880
    },
    {
      "epoch": 0.6629252893721501,
      "grad_norm": 3.608577013015747,
      "learning_rate": 6.741494212556998e-06,
      "loss": 0.7251,
      "step": 1890
    },
    {
      "epoch": 0.6664328305857594,
      "grad_norm": 5.233450412750244,
      "learning_rate": 6.671343388284813e-06,
      "loss": 0.7594,
      "step": 1900
    },
    {
      "epoch": 0.6699403717993686,
      "grad_norm": 3.303133726119995,
      "learning_rate": 6.601192564012628e-06,
      "loss": 0.7346,
      "step": 1910
    },
    {
      "epoch": 0.6734479130129779,
      "grad_norm": 2.5847628116607666,
      "learning_rate": 6.531041739740442e-06,
      "loss": 0.6886,
      "step": 1920
    },
    {
      "epoch": 0.6769554542265872,
      "grad_norm": 6.884172439575195,
      "learning_rate": 6.460890915468257e-06,
      "loss": 0.7854,
      "step": 1930
    },
    {
      "epoch": 0.6804629954401964,
      "grad_norm": 3.6329843997955322,
      "learning_rate": 6.3907400911960715e-06,
      "loss": 0.788,
      "step": 1940
    },
    {
      "epoch": 0.6839705366538057,
      "grad_norm": 2.405726194381714,
      "learning_rate": 6.320589266923887e-06,
      "loss": 0.6316,
      "step": 1950
    },
    {
      "epoch": 0.687478077867415,
      "grad_norm": 2.694972276687622,
      "learning_rate": 6.250438442651702e-06,
      "loss": 0.6459,
      "step": 1960
    },
    {
      "epoch": 0.6909856190810242,
      "grad_norm": 8.288626670837402,
      "learning_rate": 6.180287618379517e-06,
      "loss": 0.7434,
      "step": 1970
    },
    {
      "epoch": 0.6944931602946335,
      "grad_norm": 4.702238082885742,
      "learning_rate": 6.1101367941073305e-06,
      "loss": 0.7458,
      "step": 1980
    },
    {
      "epoch": 0.6980007015082427,
      "grad_norm": 4.588117599487305,
      "learning_rate": 6.039985969835146e-06,
      "loss": 0.7768,
      "step": 1990
    },
    {
      "epoch": 0.701508242721852,
      "grad_norm": 2.8334226608276367,
      "learning_rate": 5.969835145562961e-06,
      "loss": 0.7028,
      "step": 2000
    },
    {
      "epoch": 0.7050157839354613,
      "grad_norm": 3.799381732940674,
      "learning_rate": 5.899684321290776e-06,
      "loss": 0.6973,
      "step": 2010
    },
    {
      "epoch": 0.7085233251490705,
      "grad_norm": 5.292877197265625,
      "learning_rate": 5.82953349701859e-06,
      "loss": 0.8153,
      "step": 2020
    },
    {
      "epoch": 0.7120308663626798,
      "grad_norm": 5.733340740203857,
      "learning_rate": 5.7593826727464055e-06,
      "loss": 0.6918,
      "step": 2030
    },
    {
      "epoch": 0.7155384075762891,
      "grad_norm": 4.250782012939453,
      "learning_rate": 5.689231848474221e-06,
      "loss": 0.6863,
      "step": 2040
    },
    {
      "epoch": 0.7190459487898982,
      "grad_norm": 2.788475513458252,
      "learning_rate": 5.619081024202034e-06,
      "loss": 0.638,
      "step": 2050
    },
    {
      "epoch": 0.7225534900035075,
      "grad_norm": 5.862903118133545,
      "learning_rate": 5.548930199929849e-06,
      "loss": 0.7058,
      "step": 2060
    },
    {
      "epoch": 0.7260610312171168,
      "grad_norm": 5.05345344543457,
      "learning_rate": 5.4787793756576645e-06,
      "loss": 0.6645,
      "step": 2070
    },
    {
      "epoch": 0.729568572430726,
      "grad_norm": 3.241093873977661,
      "learning_rate": 5.40862855138548e-06,
      "loss": 0.681,
      "step": 2080
    },
    {
      "epoch": 0.7330761136443353,
      "grad_norm": 4.522921562194824,
      "learning_rate": 5.338477727113294e-06,
      "loss": 0.7104,
      "step": 2090
    },
    {
      "epoch": 0.7365836548579446,
      "grad_norm": 3.330577850341797,
      "learning_rate": 5.268326902841109e-06,
      "loss": 0.7819,
      "step": 2100
    },
    {
      "epoch": 0.7400911960715538,
      "grad_norm": 3.9033005237579346,
      "learning_rate": 5.1981760785689235e-06,
      "loss": 0.7515,
      "step": 2110
    },
    {
      "epoch": 0.7435987372851631,
      "grad_norm": 6.974399089813232,
      "learning_rate": 5.128025254296738e-06,
      "loss": 0.7097,
      "step": 2120
    },
    {
      "epoch": 0.7471062784987723,
      "grad_norm": 2.908669948577881,
      "learning_rate": 5.057874430024553e-06,
      "loss": 0.7759,
      "step": 2130
    },
    {
      "epoch": 0.7506138197123816,
      "grad_norm": 4.420661449432373,
      "learning_rate": 4.987723605752368e-06,
      "loss": 0.7682,
      "step": 2140
    },
    {
      "epoch": 0.7541213609259909,
      "grad_norm": 3.502258777618408,
      "learning_rate": 4.9175727814801825e-06,
      "loss": 0.7406,
      "step": 2150
    },
    {
      "epoch": 0.7576289021396001,
      "grad_norm": 3.0818893909454346,
      "learning_rate": 4.847421957207998e-06,
      "loss": 0.7083,
      "step": 2160
    },
    {
      "epoch": 0.7611364433532094,
      "grad_norm": 3.7327961921691895,
      "learning_rate": 4.777271132935812e-06,
      "loss": 0.6443,
      "step": 2170
    },
    {
      "epoch": 0.7646439845668187,
      "grad_norm": 5.354289531707764,
      "learning_rate": 4.707120308663627e-06,
      "loss": 0.7228,
      "step": 2180
    },
    {
      "epoch": 0.7681515257804279,
      "grad_norm": 3.4915177822113037,
      "learning_rate": 4.636969484391442e-06,
      "loss": 0.721,
      "step": 2190
    },
    {
      "epoch": 0.7716590669940372,
      "grad_norm": 2.647794485092163,
      "learning_rate": 4.566818660119257e-06,
      "loss": 0.7733,
      "step": 2200
    },
    {
      "epoch": 0.7751666082076465,
      "grad_norm": 4.941187381744385,
      "learning_rate": 4.496667835847072e-06,
      "loss": 0.755,
      "step": 2210
    },
    {
      "epoch": 0.7786741494212557,
      "grad_norm": 2.65548038482666,
      "learning_rate": 4.426517011574886e-06,
      "loss": 0.685,
      "step": 2220
    },
    {
      "epoch": 0.782181690634865,
      "grad_norm": 3.665707588195801,
      "learning_rate": 4.356366187302701e-06,
      "loss": 0.6789,
      "step": 2230
    },
    {
      "epoch": 0.7856892318484742,
      "grad_norm": 3.694399118423462,
      "learning_rate": 4.286215363030516e-06,
      "loss": 0.7679,
      "step": 2240
    },
    {
      "epoch": 0.7891967730620835,
      "grad_norm": 4.478413105010986,
      "learning_rate": 4.216064538758331e-06,
      "loss": 0.7009,
      "step": 2250
    },
    {
      "epoch": 0.7927043142756928,
      "grad_norm": 3.850724697113037,
      "learning_rate": 4.145913714486145e-06,
      "loss": 0.762,
      "step": 2260
    },
    {
      "epoch": 0.796211855489302,
      "grad_norm": 2.6381874084472656,
      "learning_rate": 4.07576289021396e-06,
      "loss": 0.7075,
      "step": 2270
    },
    {
      "epoch": 0.7997193967029113,
      "grad_norm": 4.226985931396484,
      "learning_rate": 4.0056120659417756e-06,
      "loss": 0.7407,
      "step": 2280
    },
    {
      "epoch": 0.8032269379165206,
      "grad_norm": 6.701294898986816,
      "learning_rate": 3.93546124166959e-06,
      "loss": 0.6627,
      "step": 2290
    },
    {
      "epoch": 0.8067344791301297,
      "grad_norm": 3.270754337310791,
      "learning_rate": 3.865310417397405e-06,
      "loss": 0.7074,
      "step": 2300
    },
    {
      "epoch": 0.810242020343739,
      "grad_norm": 5.0279107093811035,
      "learning_rate": 3.7951595931252194e-06,
      "loss": 0.6953,
      "step": 2310
    },
    {
      "epoch": 0.8137495615573483,
      "grad_norm": 4.375921726226807,
      "learning_rate": 3.7250087688530346e-06,
      "loss": 0.6448,
      "step": 2320
    },
    {
      "epoch": 0.8172571027709575,
      "grad_norm": 2.8671019077301025,
      "learning_rate": 3.654857944580849e-06,
      "loss": 0.634,
      "step": 2330
    },
    {
      "epoch": 0.8207646439845668,
      "grad_norm": 3.3584368228912354,
      "learning_rate": 3.584707120308664e-06,
      "loss": 0.6221,
      "step": 2340
    },
    {
      "epoch": 0.8242721851981761,
      "grad_norm": 4.914835453033447,
      "learning_rate": 3.514556296036479e-06,
      "loss": 0.6335,
      "step": 2350
    },
    {
      "epoch": 0.8277797264117853,
      "grad_norm": 3.0727927684783936,
      "learning_rate": 3.444405471764293e-06,
      "loss": 0.6189,
      "step": 2360
    },
    {
      "epoch": 0.8312872676253946,
      "grad_norm": 3.2750375270843506,
      "learning_rate": 3.3742546474921083e-06,
      "loss": 0.7075,
      "step": 2370
    },
    {
      "epoch": 0.8347948088390038,
      "grad_norm": 3.9428796768188477,
      "learning_rate": 3.304103823219923e-06,
      "loss": 0.7393,
      "step": 2380
    },
    {
      "epoch": 0.8383023500526131,
      "grad_norm": 2.482280969619751,
      "learning_rate": 3.2339529989477382e-06,
      "loss": 0.7889,
      "step": 2390
    },
    {
      "epoch": 0.8418098912662224,
      "grad_norm": 5.964336395263672,
      "learning_rate": 3.1638021746755525e-06,
      "loss": 0.7898,
      "step": 2400
    },
    {
      "epoch": 0.8453174324798316,
      "grad_norm": 2.261914014816284,
      "learning_rate": 3.0936513504033677e-06,
      "loss": 0.6776,
      "step": 2410
    },
    {
      "epoch": 0.8488249736934409,
      "grad_norm": 5.0676164627075195,
      "learning_rate": 3.0235005261311825e-06,
      "loss": 0.7181,
      "step": 2420
    },
    {
      "epoch": 0.8523325149070502,
      "grad_norm": 6.481790542602539,
      "learning_rate": 2.953349701858997e-06,
      "loss": 0.6926,
      "step": 2430
    },
    {
      "epoch": 0.8558400561206594,
      "grad_norm": 5.835069179534912,
      "learning_rate": 2.883198877586812e-06,
      "loss": 0.6824,
      "step": 2440
    },
    {
      "epoch": 0.8593475973342687,
      "grad_norm": 4.172300815582275,
      "learning_rate": 2.8130480533146263e-06,
      "loss": 0.6813,
      "step": 2450
    },
    {
      "epoch": 0.862855138547878,
      "grad_norm": 3.192988395690918,
      "learning_rate": 2.7428972290424415e-06,
      "loss": 0.6558,
      "step": 2460
    },
    {
      "epoch": 0.8663626797614872,
      "grad_norm": 4.364963531494141,
      "learning_rate": 2.6727464047702562e-06,
      "loss": 0.6775,
      "step": 2470
    },
    {
      "epoch": 0.8698702209750965,
      "grad_norm": 7.955432415008545,
      "learning_rate": 2.6025955804980714e-06,
      "loss": 0.727,
      "step": 2480
    },
    {
      "epoch": 0.8733777621887057,
      "grad_norm": 6.076704502105713,
      "learning_rate": 2.5324447562258857e-06,
      "loss": 0.767,
      "step": 2490
    },
    {
      "epoch": 0.876885303402315,
      "grad_norm": 3.602504253387451,
      "learning_rate": 2.4622939319537005e-06,
      "loss": 0.6319,
      "step": 2500
    },
    {
      "epoch": 0.8803928446159243,
      "grad_norm": 2.1571288108825684,
      "learning_rate": 2.3921431076815156e-06,
      "loss": 0.7401,
      "step": 2510
    },
    {
      "epoch": 0.8839003858295335,
      "grad_norm": 3.820662498474121,
      "learning_rate": 2.3219922834093304e-06,
      "loss": 0.7779,
      "step": 2520
    },
    {
      "epoch": 0.8874079270431428,
      "grad_norm": 5.471105575561523,
      "learning_rate": 2.251841459137145e-06,
      "loss": 0.7457,
      "step": 2530
    },
    {
      "epoch": 0.890915468256752,
      "grad_norm": 5.591996192932129,
      "learning_rate": 2.18169063486496e-06,
      "loss": 0.6943,
      "step": 2540
    },
    {
      "epoch": 0.8944230094703612,
      "grad_norm": 3.893911123275757,
      "learning_rate": 2.1115398105927746e-06,
      "loss": 0.7278,
      "step": 2550
    },
    {
      "epoch": 0.8979305506839705,
      "grad_norm": 6.013058662414551,
      "learning_rate": 2.0413889863205894e-06,
      "loss": 0.6677,
      "step": 2560
    },
    {
      "epoch": 0.9014380918975798,
      "grad_norm": 5.568266868591309,
      "learning_rate": 1.971238162048404e-06,
      "loss": 0.7162,
      "step": 2570
    },
    {
      "epoch": 0.904945633111189,
      "grad_norm": 2.5080010890960693,
      "learning_rate": 1.901087337776219e-06,
      "loss": 0.7539,
      "step": 2580
    },
    {
      "epoch": 0.9084531743247983,
      "grad_norm": 3.6320009231567383,
      "learning_rate": 1.8309365135040338e-06,
      "loss": 0.6792,
      "step": 2590
    },
    {
      "epoch": 0.9119607155384076,
      "grad_norm": 4.286765098571777,
      "learning_rate": 1.7607856892318486e-06,
      "loss": 0.8071,
      "step": 2600
    },
    {
      "epoch": 0.9154682567520168,
      "grad_norm": 2.993039846420288,
      "learning_rate": 1.6906348649596636e-06,
      "loss": 0.713,
      "step": 2610
    },
    {
      "epoch": 0.9189757979656261,
      "grad_norm": 4.428566932678223,
      "learning_rate": 1.6204840406874783e-06,
      "loss": 0.7132,
      "step": 2620
    },
    {
      "epoch": 0.9224833391792353,
      "grad_norm": 4.264359474182129,
      "learning_rate": 1.5503332164152928e-06,
      "loss": 0.6534,
      "step": 2630
    },
    {
      "epoch": 0.9259908803928446,
      "grad_norm": 3.9837441444396973,
      "learning_rate": 1.4801823921431078e-06,
      "loss": 0.7164,
      "step": 2640
    },
    {
      "epoch": 0.9294984216064539,
      "grad_norm": 3.279191255569458,
      "learning_rate": 1.4100315678709226e-06,
      "loss": 0.7018,
      "step": 2650
    },
    {
      "epoch": 0.9330059628200631,
      "grad_norm": 3.4879727363586426,
      "learning_rate": 1.3398807435987373e-06,
      "loss": 0.6942,
      "step": 2660
    },
    {
      "epoch": 0.9365135040336724,
      "grad_norm": 4.424973964691162,
      "learning_rate": 1.2697299193265523e-06,
      "loss": 0.7636,
      "step": 2670
    },
    {
      "epoch": 0.9400210452472817,
      "grad_norm": 3.6979403495788574,
      "learning_rate": 1.199579095054367e-06,
      "loss": 0.6191,
      "step": 2680
    },
    {
      "epoch": 0.9435285864608909,
      "grad_norm": 3.6198480129241943,
      "learning_rate": 1.1294282707821818e-06,
      "loss": 0.6932,
      "step": 2690
    },
    {
      "epoch": 0.9470361276745002,
      "grad_norm": 3.629969596862793,
      "learning_rate": 1.0592774465099965e-06,
      "loss": 0.7224,
      "step": 2700
    },
    {
      "epoch": 0.9505436688881095,
      "grad_norm": 5.298070907592773,
      "learning_rate": 9.891266222378115e-07,
      "loss": 0.7208,
      "step": 2710
    },
    {
      "epoch": 0.9540512101017187,
      "grad_norm": 4.7321085929870605,
      "learning_rate": 9.189757979656262e-07,
      "loss": 0.6327,
      "step": 2720
    },
    {
      "epoch": 0.957558751315328,
      "grad_norm": 3.248121500015259,
      "learning_rate": 8.488249736934409e-07,
      "loss": 0.6581,
      "step": 2730
    },
    {
      "epoch": 0.9610662925289372,
      "grad_norm": 5.854094505310059,
      "learning_rate": 7.786741494212557e-07,
      "loss": 0.6932,
      "step": 2740
    },
    {
      "epoch": 0.9645738337425465,
      "grad_norm": 3.5251548290252686,
      "learning_rate": 7.085233251490706e-07,
      "loss": 0.6952,
      "step": 2750
    },
    {
      "epoch": 0.9680813749561558,
      "grad_norm": 8.667288780212402,
      "learning_rate": 6.383725008768854e-07,
      "loss": 0.6828,
      "step": 2760
    },
    {
      "epoch": 0.971588916169765,
      "grad_norm": 2.9134840965270996,
      "learning_rate": 5.682216766047002e-07,
      "loss": 0.658,
      "step": 2770
    },
    {
      "epoch": 0.9750964573833742,
      "grad_norm": 2.5814292430877686,
      "learning_rate": 4.980708523325149e-07,
      "loss": 0.6926,
      "step": 2780
    },
    {
      "epoch": 0.9786039985969835,
      "grad_norm": 3.6542952060699463,
      "learning_rate": 4.2792002806032974e-07,
      "loss": 0.6707,
      "step": 2790
    },
    {
      "epoch": 0.9821115398105927,
      "grad_norm": 4.765872955322266,
      "learning_rate": 3.577692037881445e-07,
      "loss": 0.7431,
      "step": 2800
    },
    {
      "epoch": 0.985619081024202,
      "grad_norm": 5.806207180023193,
      "learning_rate": 2.8761837951595935e-07,
      "loss": 0.6964,
      "step": 2810
    },
    {
      "epoch": 0.9891266222378113,
      "grad_norm": 3.874917507171631,
      "learning_rate": 2.1746755524377415e-07,
      "loss": 0.6722,
      "step": 2820
    },
    {
      "epoch": 0.9926341634514205,
      "grad_norm": 3.098463773727417,
      "learning_rate": 1.4731673097158893e-07,
      "loss": 0.7506,
      "step": 2830
    },
    {
      "epoch": 0.9961417046650298,
      "grad_norm": 4.226992607116699,
      "learning_rate": 7.716590669940373e-08,
      "loss": 0.7111,
      "step": 2840
    },
    {
      "epoch": 0.9996492458786391,
      "grad_norm": 2.388195037841797,
      "learning_rate": 7.0150824272185196e-09,
      "loss": 0.7157,
      "step": 2850
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.678,
      "eval_loss": 0.7078991532325745,
      "eval_runtime": 105.4343,
      "eval_samples_per_second": 18.969,
      "eval_steps_per_second": 1.186,
      "step": 2851
    }
  ],
  "logging_steps": 10,
  "max_steps": 2851,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1177338429289008.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
